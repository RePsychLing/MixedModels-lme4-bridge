{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introducing JellyMe4\n### [\"Phillip M. Alday\"]\n### April 2020\n`JellyMe4` is brand new. The basic functionality is there and works quite well for linear mixed models and some things with Bernoulli (binomial) models, but there's still a lot of work to be done. You can install it in Julia with:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "julia>] add JellyMe4"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is relatively little only help via the Julia help (`?`) because creating this type of bridge mostly involves defining methods for the functions RCall uses in the background. These functions are then invoked via `@rget`, `@rput`, `R\"some_command\"`, and `rcopy`), and the documentation for those is (intentionally) generic.\n\nThere is however documentation available in the [README](https://github.com/palday/JellyMe4.jl) and some error checking that will catch common mistakes and suggest what you might actually want to do. We'll see that in some examples below.\n\n# Preprocessing of Many Babies Data\n\n(borrowed from https://github.com/RePsychLing/mb1/blob/MB1_analysis.jmd at commit `479db01 `)"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using CSV            # read and write .csv files\nusing Gadfly         # plotting\nusing DataFrames\nusing DataFramesMeta # dplyr-like operations\nusing MixedModels\nusing StatsBase      # basic statistics functions\nusing RCall          # Call R from Julia\nusing JellyMe4       # see https://github.com/palday/JellyMe4.jl\nR\"\"\"\nlibrary(\"lme4\")\nlibrary(\"lattice\")\nlibrary(\"effects\")\nlibrary(\"car\")\nlibrary(\"sjPlot\")\n\"\"\""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are working with the *ManyBabies 1 - Infant-directed Speech Preference* dataset that has been published at:\nhttps://github.com/manybabies/mb1-analysis-public"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "mb1 = CSV.read(\n    download(\"https://raw.githubusercontent.com/manybabies/mb1-analysis-public/fa7e77c026a4dc0b0bb7e78d3bf3771c9bc2f7cb/processed_data/03_data_trial_main.csv\"),\n    missingstrings=[\"NA\",\"N/A\"],\n    truestrings=[\"TRUE\"],\n    falsestrings=[\"FALSE\"]);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recode the levels of `gender`, add the `item` variable (join condition and stimulus information), center the `age_mo`, and relevel `method` and `age_group`.\nAdd log-transformed looking time `log_lt` for visualization. Drop observations with a missing response (`looking_time`)."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "mb1a = @linq mb1 |>\n    transform(gender = recode(:gender, \"0\"=>missing, \"MALE\"=>\"M\", \"FEMALE\"=>\"F\"),\n              item = string.(:stimulus_num, :trial_type),\n              age_mo = :age_mo .- mean(:age_mo),\n              log_lt = log.(:looking_time),\n              method = levels!(categorical(:method), [\"singlescreen\", \"eyetracking\", \"hpp\"]),\n              age_group = levels!(categorical(:age_group), [\"3-6 mo\", \"6-9 mo\", \"9-12 mo\", \"12-15 mo\"])) |>\n    where(.!ismissing.(:looking_time));\ndisallowmissing!(mb1a, error=false);\ndescribe(mb1a)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fit some models in Julia\n\n## Intercepts only\nFit the linear mixed-effects model from the paper. We replicate the reported results."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "m1form = @formula log(looking_time) ~ trial_type * method +\n                   trial_type * trial_num +\n                   age_mo * trial_num +\n                   trial_type * age_mo * nae +\n                   (1 | subid_unique) +\n                   (1 | lab) +\n                   (1 | item);\nm1 = fit(MixedModel, m1form, mb1a, REML=true)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The thresholding of the response produces some unusual patterns in the residuals versus fitted values."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(x=fitted(m1), y=residuals(m1), Geom.density2d)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preregistered maximal model\n\nFit the authors' intended maximal mixed-effects model. lme4 in R did initally not converge and now throws singularity warnings for this model.\nWe switch from REML to ML."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "m2form = @formula log(looking_time) ~ trial_type * method +\n                   trial_type * trial_num +\n                   age_mo * trial_num +\n                   trial_type * age_mo * nae +\n                   (1 + trial_type * trial_num | subid_unique) +\n                   (1 + trial_type * age_mo | lab) +\n                   (1 + method + age_mo * nae | item);\nm2 = LinearMixedModel(m2form, mb1a)\nm2.optsum.initial = θ₀\nfit!(m2)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Move models from Julia to R\n\nWe start with the simple model, because like everything else in Julia, the first time you do something using `JellyMe4`, you have to wait for the JIT.\n\nWe first have to define a Tuple that wraps the fitted model and its data source (usually a `DataFrame`). MixedModels doesn't keep a copy of the 'raw' data stored in a convenient way and the internal structures are different enough that it would be a LOT of work to convert them directly. Instead, we create a model in lme4 and use the `theta` vector from MixedModels as a starting point and allow one optimizer step.\n\nIn other words, this isn't instantaneous -- we have to shuffle data back-and-forth and wait for a single step of the optimizer, which for large models isn't fast."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "m1r = Tuple([m1,mb1a])\n@rput m1r;\nR\"summary(m1r)\""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "As stated above, there is some error catching for common mistakes:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@rput m1"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model we've created in R is a real lme4 model, and we can do all the usual stuff with it. Let's do that with the more complicated model."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "m2r = Tuple([m2,mb1a])\n@time @rput m2r;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "m1.optsum.feval"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "R\"m1r@optinfo$feval\""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "R\"summary(m2r)\""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "R\"plot(m2r)\""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "R\"dotplot(ranef(m2r,condVar=TRUE))\""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "R\"qqmath(m2r)\""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because it's a proper `merMod` model, we instantly get access to all packages supporting `merMod`.\n\n### Effects"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "R\"\"\"\neff <- Effect(c(\"trial_type\", \"age_mo\", \"nae\"), m2r, KR=FALSE)\nplot(eff, rug=FALSE)\n\"\"\""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CAR"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "R\"Anova(m2r, type=2)\""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### lmerTest\n\nBut seriously, don't do this. It makes us cry.\n\nAnd if you try to do the Kenward-Roger ddf correction on this model, it will also make you try because there's this line of code in there:\n\n\n```{R; eval=false}\n## print(\"HHHHHHHHHHHHHHH\")\nSigmaInv <- chol2inv( chol( forceSymmetric(SigmaG$Sigma) ) )\n## print(\"DONE --- HHHHHHHHHHHHHHH\")\n```\n[from source code of `pbkrtest`](https://github.com/hojsgaard/pbkrtest/blob/d44880463a2b2855cda1f60fda030bd5373a97e3/R/KR-vcovAdj.R#L109-L111)\n\nIn other words, a naive inverse on a large, unstructured matrix. Noooooooooooooooooooo ..... you still have several yearsof 'oooo'ing and hundreds more gigabytes of memory to go ....."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "R\"\"\"\nlibrary(\"lmerTest\")\nabomination1 <- as(m1r, \"merModLmerTest\")\nsummary(abomination1, ddf=\"Satterthwaite\")\n\"\"\""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### lmerOut\n\nAnd some gratuitous self-advertising. Checkout my [`lmerOut`](https://bitbucket.org/palday/lmerout) package for generating HTML or LaTeX output from `merMod`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "R\"\"\"library(\"lmerOut\")\"\"\""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "HTML(rcopy(R\"\"\"pprint(m2r,type=\"html\")\"\"\"))"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "HTML(rcopy(R\"\"\"pprint(summary(m2r),type=\"html\")\"\"\"))"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "HTML(rcopy(R\"\"\"pprint(Anova(m2r),type=\"html\")\"\"\"))"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fit some models in R"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "R\"\"\"\nmsleep <- lme4::lmer(Reaction ~ 1 + Days + (1 + Days | Subject), sleepstudy, REML=FALSE)\nsummary(msleep)\n\"\"\""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "R\"\"\"msleep@optinfo$feval\"\"\""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Move models from R to Julia"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@rget msleep"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "msleep.optsum"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What won't work:\n\n1. Most transformations within model formulae, especially things like R's `scale` which acts on all values in a column simultaneously. Transform ahead of time.\n2. Contrast coding. I'm working on this, but it's really non-trivial, especially if you want meaningful names preserved. So you have two options\n    1. Fund another two-week retreat for me and Dave where we're not doing any of the other stuff (including all of the other Julia-related stuff we're already tapped for).\n    2. Set up numeric predictors by hand.\n3. Missing data is handled differently in Julia and R. Solution:\n    1. Reduce your dataframe down to the columns you need (which will speed up things because there's less to push pack and forth across the bridge).\n    2. Remove the rows that still contain missing data.\n    3. (Profit).\n4. \"Advanced\" models using `zerocorr` or other variance-structure transformations in Julia or `||` in R. `zerocorr` and `||` aren't directly equivalent and adding in the extra machinery to yield equivalent results is time I'm not working on `MixedModels` proper or GLMM support (see next point).\n5. GLMMs with one exception (see below).\n\nAnd a final word of warning: JellyMe4 uses several variables prefixed `jellyme4_` in R as a scratch space. Once you've moved something across the bridge, these can be removed. Generally, they will be quite small, with the exception of the model, but as long as you don't call `update()` on a model, the extra copy of the model won't take up additional space.\n\n# Generalized Linear Mixed Models\n\nRight now, there is *extremely* limited support for GLMMs.\n\nAnd I mean **extremely**.\n\nYou can take a Bernoulli model in Julia (i.e. a Binomial model fit to `0`s and `1`s at the single-trial/observation level) and move it to R. Because of (insert lots of math and computer science here), you tend to lose some a bit of fidelity in the translation, **but** the model is still close enough for plotting purposes.\n\nAnd that's it.\n\nI'm jobless starting 1 June, so pay me and we'll see about supporting more."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "verbagg = MixedModels.dataset(:verbagg)\nglmm_form = @formula(r2 ~ 1 + anger + gender + btype + situ + (1|subj) + (1|item));"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "fast = fit!(GeneralizedLinearMixedModel(glmm_form, verbagg, Bernoulli()), fast=true)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "mlogit = Tuple([fast, verbagg]);\n@rput mlogit;\nR\"summary(mlogit)\""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "import GLM: ProbitLink"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "slow = fit!(GeneralizedLinearMixedModel(glmm_form, verbagg, Bernoulli(), ProbitLink()), fast=false);"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "mprobit = Tuple([slow, verbagg]);\n@rput mprobit;\nR\"summary(mprobit)\""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "R\"\"\"\nplot_model(mprobit, type = \"pred\", terms = c(\"anger\", \"gender\"))\n\"\"\""
      ],
      "metadata": {},
      "execution_count": null
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.4.0"
    },
    "kernelspec": {
      "name": "julia-1.4",
      "display_name": "Julia 1.4.0",
      "language": "julia"
    }
  },
  "nbformat": 4
}
